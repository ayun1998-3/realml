<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>datastreams-api</title>
    <!-- <script src="https://cdn.jsdelivr.net/npm/@brainsatplay/ganglion"></script> -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/datastreams-api"></script> -->
    <script src="./libraries/ml.min.js"></script>
    <!-- <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.0.2/dist/tfjs-vis.umd.min.js"></script>


</head>

<body style="padding: 10px;">
    <p><a href="index.html">Home</a></p>

    <h1>datastreams-api</h1>
    <hr>
    <br>

    <p>Press 'B' to record while blinking. Press 'O' to record while eyes are open.</p>

    <div id="buttons">
        <button id="device">Synthetic</button>
        <button id="muse">Muse</button>
        <button id="ganglion">Ganglion</button>
        <button id="hegduino">HEGduino</button>
    </div>
    <div id="graph">

    </div>

    <div id="trainingUI">

    </div>


</body>

<script type="module">

    // ------------- Import Libraries -------------

    // User Interface
    import * as components from "https://cdn.jsdelivr.net/npm/brainsatplay-ui@0.0.7/dist/index.esm.js"


    // const end = document.createElement('button')
    // end.innerHTML = 'End Recording'
    // trainingUI.insertAdjacentElement('beforeend', end)
    const train = document.createElement('button')
    train.innerHTML = 'Train Model'
    trainingUI.insertAdjacentElement('beforeend', train)
    const test = document.createElement('button')
    test.innerHTML = 'Test Model'
    trainingUI.insertAdjacentElement('beforeend', test)


    // Data Acquisition
    // import * as datastreams from "./src/frontend/dist/index.esm.js"
    import * as datastreams from "https://cdn.jsdelivr.net/npm/datastreams-api@latest/dist/index.esm.js"
    const dataDevices = new datastreams.DataDevices()

    // Device Drivers
    import ganglion from "https://cdn.jsdelivr.net/npm/@brainsatplay/ganglion@0.0.2/dist/index.esm.js"
    import muse from "https://cdn.jsdelivr.net/npm/@brainsatplay/muse@0.0.1/dist/index.esm.js"
    import device from "https://cdn.jsdelivr.net/npm/@brainsatplay/device@0.0.2/dist/index.esm.js"
    import hegduino from "https://cdn.jsdelivr.net/npm/@brainsatplay/hegduino@0.0.4/dist/index.esm.js"

    // Local Libraries
    import * as timer from './src/time.js'
    import * as ml from './src/ml.js'
    import * as ml5 from './libraries/ml.min.js'


    // ml.tfTrain()
    dataDevices.load(muse)
    dataDevices.load(device)
    dataDevices.load(ganglion)
    dataDevices.load(hegduino)

    // ------------- Setup Visualization (very rough) -------------
    const graphDiv = document.getElementById('graph')
    graphDiv.style.padding = '25px'
    let timeseries


    // ------------- Declare Global Variables -------------
    let sampleData = []
    const training = []
    const labels = []
    const windowSize = 5
    let channels = 0
    let trackMap = new Map()
    let contentHintToIndex = {}
    // let endStream = false
    let deviceType = 'device'
    let channelCount = 3
    let sample = 0
    let testing = false
    const testdata = []
    const class1 = 'Blinking'
    const class2 = 'Eyes Open'

    let counter = 0
    let g = 0
    let ultrasum = 0

    // ------------- Declare Data Handler -------------
    const ondata = (data, timestamps, contentHint) => {
        // console.log(`Data from Electrode ${contentHintToIndex[contentHint]} (${contentHint})`, data, timestamps)

        // if (contentHint === 'AF7') { // printing out avg values for data samples to see if it helps (did not help)
        //     g ++
        //     let sampleVal = data.reduce((x, y) => x + y)/12
        //     // console.log(sampleVal)
        //     ultrasum += sampleVal
        //     if (g === 10) {
        //         console.log('ultra', ultrasum/10)
        //         ultrasum = 0
        //         g = 0
        //     }
        //     // if (g === 10) {
        //     //     const avg = data.reduce((x, y) => x + y)/12
        //     //     console.log(avg)
        //     //     g = 0
        //     // }
        // }
        if (pressed) {
            // sampleData[contentHintToIndex[contentHint]].push(data)

            for (let i = 0; i < 12; i++) {
                if (typeof sampleData[counter + i] === 'undefined') {
                    sampleData.push([])
                }
                const value = data[i]
                sampleData[counter + i].push(value)
            }

            if (sampleData[counter].length === 4) counter += 12
        }

        if (testing) testdata[contentHintToIndex[contentHint]].push(data)
    }

    // ------------- Declare Track Handler -------------
    const handleTrack = (track) => {


        // ------------- Map Track Information (e.g. 10-20 Coordinate) to Index -------------
        if (!trackMap.has(track.contentHint)) {
            const index = trackMap.size
            contentHintToIndex[track.contentHint] = index
            trackMap.set(index, track)
        }

        // ------------- Grab Index -------------
        const i = contentHintToIndex[track.contentHint]
        // console.log(track.contentHint, i)
        channels = (i > channels) ? i : channels // Assign channels as max track number

        // ------------- Subscribe to New Data -------------
        track.subscribe((data, timestamps) => {

            // Organize New Data
            let arr = []
            for (let j = 0; j <= channels; j++) (i === j) ? arr.push(data) : arr.push([])

            // Add Data to Timeseries Graph
            timeseries.data = arr
            timeseries.seconds = "20"
            timeseries.draw() // FORCE DRAW: Update happens too fast for UI

            // Run ondata Callback
            ondata(data, timestamps, track.contentHint)
            // if (pressed) {
            //     if (dataType === 'Blink') {
            //         labels.push('blink')
            //     }
            //     else if (dataType === 'Open') {
            //         labels.push('open')
            //     }
            // }
        })
    }

    // ------------- Declare Acquisition Function -------------

    const startAcquisition = async (label) => {

        timeseries = new components.streams.data.TimeSeries()
        graphDiv.insertAdjacentElement('beforeend', timeseries)



        // ------------- Get Device Stream -------------

        // Method #1: By Label
        const dataDevice = await dataDevices.getUserDevice({ label, bluetooth: true })
        console.log(dataDevice)

        // Method #2: By Class
        // const dataDevice = await dataDevices.getUserDevice(ganglion)

        // ------------- Grab DataStream from Device -------------
        const stream = dataDevice.stream
        console.log(stream)

        // ------------- Handle All Tracks -------------
        stream.tracks.forEach(handleTrack)
        stream.onaddtrack = e => handleTrack(e.track)

        // wait for endStream to be true and then end stream
        // let delay1 = await setInterval(() => {
        //     if (endStream) {
        //         stream.tracks.forEach(track => stream.removeTrack(track))
        //         clearInterval(delay1)
        //     }
        // })



        // stream.removeTrack()
    }

    // ------------- Set Button Functionality -------------
    const buttons = document.querySelector('#buttons')
    for (let button of buttons.querySelectorAll('button')) {
        button.onclick = () => {

            deviceType = button.id
            switch (deviceType) {
                case 'device': channelCount = 3
                    break
                case 'muse': channelCount = 4
                    break
                case 'ganglion': channelCount = 0
                    break
                case 'hegduino': channelCount = 0
                    break
            }
            console.log(button.id)
            console.log(channelCount)
            // for (let i = 0; i < channelCount; i++) {
            //     training.push([])
            // }
            startAcquisition(button.id)
        }
    }

    // end.onclick = () => {
    //     endStream = true
    // }

    let pressed = false // indicate whether key is already pressed
    window.onkeydown = (ev) => {


        if (!pressed && (ev.code === 'KeyB' || ev.code === 'KeyO')) {
            // endStream = false

            if (ev.code === 'KeyB') {
                console.log('recording blinks')
                // labels.push('blink')
            }

            else if (ev.code === 'KeyO') {
                console.log('recording eyes open')
                // labels.push('open')
            }

            // training.push([]) //create new sample
            // for (let i = 0; i < channelCount; i++) {
            //     sampleData.push([])
            // }
            pressed = true
        }
    }

    window.onkeyup = (ev) => {
        if (ev.code === 'KeyB' || ev.code === 'KeyO') {
            console.log('recording ended')

            console.log('sampleData', sampleData)
            // const segmentedData = []

            for (let i = 0; i < sampleData.length - 60; i += 60) {
                const sample = sampleData.slice(i, i + 60)
                training.push(sample)
                if (ev.code === 'KeyB') labels.push([1, 0])
                else labels.push([0, 1])
            }
            // for (let i = 0; i < sampleData[0].length - windowSize; i += (windowSize - 1)) {
            //     const temp = []
            //     for (let c = 0; c < sampleData.length; c++) {
            //         temp.push(sampleData[c].slice(i, i + windowSize).flat())   //DATA IS 4 x 60 now
            //         if (c === 0) {                                  // Only runs for the first channel
            //             if (ev.code === 'KeyB') labels.push([1, 0])
            //             else labels.push([0, 1])
            //         }
            //     }
            //     segmentedData.push(temp)
            // }
            // console.log(segmentedData)

            // segmentedData.forEach(value => { training.push(value) })

            console.log(training)

            // console.log('Training: ', training)
            // console.log('Labels: ', labels)
            // sample++
            // sampleData = []
            pressed = false
        }
    }

    train.onclick = () => {
        ml.tfTrain(training, labels)
        // ml.trainNN(training, labels)
    }

    test.onclick = async () => {

        testing = true
        for (let i = 0; i < channelCount; i++) {
            testdata.push([])
        }
        let testLoop = await setInterval(async () => {
            const temp = []
            // const testWindow = []
            // for (let c = 0; c < testdata.length; c++) {
            //     testWindow.push(testdata[c].slice((-1) * (windowSize)))
            // }

            // const testWindows = []
            // for (let i = 0; i < 3; i++) {
            //     let j = testdata[0].length + 1
            //     const testWindow = testdata.map(channel => channel.slice((-1) * (windowSize) - i, i == 0 ? (j) : (-1 * i)))
            //     testWindows.push(testWindow)
            // }
            const testWindow = testdata.map(channel => channel.slice((-1) * (windowSize)).flat())
            console.log(testWindow)

            let results = await ml.tfTest(testWindow)
            // console.log(results, results[0])
            const maxPossibility = Math.max(...results[0])
            console.log(results[0])

            let prediction = class2
            if (maxPossibility === results[0]) {
                prediction = class1
            }
            let p = document.createElement('p')
            document.body.insertAdjacentElement('beforeend', p)
            p.innerHTML = `Prediction: ${prediction} \n Confidence: ${maxPossibility}`

        }, 500)
    }

</script>

</html>